{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkJAhOCMQFNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs6hVXXAQFN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC2zkEBQQFOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6dd211f9-490a-4456-ff90-6f0ee27db828"
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAR6T3FFQFOU",
        "colab_type": "text"
      },
      "source": [
        "_A primeira etapa do trabalho consiste em dividir o conjunto de dados em duas partes A e B. Na parte B você irá selecionar todas as imagens pertencentes a 2 das 10 classes e na parte A ficarão as imagens das demais 8 classes. As classes selecionadas na parte B serão as de número x e y, onde x e y são os dois últimos dígitos do seu número de matrícula._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEfbCASAQFOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B_train = np.array([idx for idx, y in enumerate(y_train) if y[0] in (4,2)]) # 2017014642\n",
        "A_train = np.array([idx for idx, y in enumerate(y_train) if idx not in B_train])\n",
        "\n",
        "B_test = np.array([idx for idx, y in enumerate(y_test) if y[0] in (4,2)]) # 2017014642\n",
        "A_test = np.array([idx for idx, y in enumerate(y_test) if idx not in B_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCX8YfpQQFOl",
        "colab_type": "text"
      },
      "source": [
        "Feito isto, você deverá treinar uma CNN para classificação das imagens usando os dados da parte A e a API do Keras para o TensorFlow. A CNN deverá ter quatro camadas de convolução e duas camadas de Max Pooling (não necessariamente nessa ordem) e duas camadas Fully Connected ao final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck1jrS_xu18h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn6dKTbPJAEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "92a4fef4-c74a-4142-85af-255112e84a66"
      },
      "source": [
        "y_train[A_train][:,[0,1,3,5]]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0JSfLV1OWOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "def create_model(img_shape, num_classes,\n",
        "                 dropout_conv=0.25, dropout_classif=0.25):\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Convolução\n",
        "    model.add(Conv2D(filters=16, \n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     input_shape=img_shape,\n",
        "                     activation='relu'))\n",
        "    \n",
        "    # Convolução\n",
        "    model.add(Conv2D(filters=32,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     activation='relu'))\n",
        "    \n",
        "    # Max Pooling\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(dropout_conv))\n",
        "  \n",
        "    # Convolução\n",
        "    model.add(Conv2D(filters=64,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     activation='relu'))\n",
        "    \n",
        "    # Convolução\n",
        "    model.add(Conv2D(filters=128,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     activation='relu'))\n",
        "    \n",
        "    # Max Pooling\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(dropout_conv))\n",
        "  \n",
        "    # Fully Connected\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(dropout_classif))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoJNsH05QFOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4a71b63-f52c-43ab-ea9f-303d98377c2e"
      },
      "source": [
        "from keras.optimizers import rmsprop\n",
        "\n",
        "modelA = create_model(x_train.shape[1:], 8)\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "modelA.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "modelA.fit(x_train[A_train], y_train[A_train][:,[0,1,3,5,6,7,8,9]], epochs=20, validation_data=(x_test[A_test], y_test[A_test][:,[0,1,3,5,6,7,8,9]]), verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0702 05:06:42.160763 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0702 05:06:42.178086 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0702 05:06:42.180373 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0702 05:06:42.206931 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0702 05:06:42.209259 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0702 05:06:42.219278 140451537737600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0702 05:06:42.324047 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0702 05:06:42.333041 140451537737600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0702 05:06:42.500514 140451537737600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 8000 samples\n",
            "Epoch 1/20\n",
            " - 13s - loss: 12.2034 - acc: 0.1506 - val_loss: 1.7377 - val_acc: 0.4151\n",
            "Epoch 2/20\n",
            " - 10s - loss: 1.3964 - acc: 0.4743 - val_loss: 1.2031 - val_acc: 0.5591\n",
            "Epoch 3/20\n",
            " - 10s - loss: 1.1289 - acc: 0.5837 - val_loss: 1.0196 - val_acc: 0.6191\n",
            "Epoch 4/20\n",
            " - 10s - loss: 1.0121 - acc: 0.6313 - val_loss: 0.9816 - val_acc: 0.6544\n",
            "Epoch 5/20\n",
            " - 10s - loss: 0.9342 - acc: 0.6623 - val_loss: 0.8479 - val_acc: 0.6949\n",
            "Epoch 6/20\n",
            " - 10s - loss: 0.8822 - acc: 0.6843 - val_loss: 0.9253 - val_acc: 0.6745\n",
            "Epoch 7/20\n",
            " - 10s - loss: 0.8397 - acc: 0.6977 - val_loss: 0.8387 - val_acc: 0.7007\n",
            "Epoch 8/20\n",
            " - 10s - loss: 0.8198 - acc: 0.7093 - val_loss: 0.8188 - val_acc: 0.7143\n",
            "Epoch 9/20\n",
            " - 10s - loss: 0.7924 - acc: 0.7194 - val_loss: 0.8226 - val_acc: 0.7151\n",
            "Epoch 10/20\n",
            " - 10s - loss: 0.7757 - acc: 0.7289 - val_loss: 0.7796 - val_acc: 0.7199\n",
            "Epoch 11/20\n",
            " - 10s - loss: 0.7611 - acc: 0.7329 - val_loss: 0.7359 - val_acc: 0.7388\n",
            "Epoch 12/20\n",
            " - 10s - loss: 0.7467 - acc: 0.7386 - val_loss: 0.7437 - val_acc: 0.7432\n",
            "Epoch 13/20\n",
            " - 10s - loss: 0.7397 - acc: 0.7441 - val_loss: 0.7224 - val_acc: 0.7514\n",
            "Epoch 14/20\n",
            " - 10s - loss: 0.7262 - acc: 0.7492 - val_loss: 0.7330 - val_acc: 0.7505\n",
            "Epoch 15/20\n",
            " - 10s - loss: 0.7216 - acc: 0.7509 - val_loss: 0.7732 - val_acc: 0.7409\n",
            "Epoch 16/20\n",
            " - 10s - loss: 0.7155 - acc: 0.7541 - val_loss: 0.7107 - val_acc: 0.7575\n",
            "Epoch 17/20\n",
            " - 10s - loss: 0.7083 - acc: 0.7567 - val_loss: 0.6936 - val_acc: 0.7654\n",
            "Epoch 18/20\n",
            " - 10s - loss: 0.7078 - acc: 0.7590 - val_loss: 0.7071 - val_acc: 0.7570\n",
            "Epoch 19/20\n",
            " - 10s - loss: 0.7019 - acc: 0.7591 - val_loss: 0.7773 - val_acc: 0.7428\n",
            "Epoch 20/20\n",
            " - 10s - loss: 0.6975 - acc: 0.7605 - val_loss: 0.7262 - val_acc: 0.7522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd220f4b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDRet9gCHdOI",
        "colab_type": "text"
      },
      "source": [
        "- [ ] Sem Transfer Learning:  Treinar a rede do zero, inicializando os pesos aleatoriamente.\n",
        "- [ ] Fine-tuning em uma camada: Utilizar os pesos da  rede  treinada na parte A e realizar fine-tuning na última camada Fully Connected.\n",
        "- [ ] Fine-tuning em duas camadas: Utilizar os pesos da rede treinada na parte A e realizar fine-tuning nas duas camadas Fully Connected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGHlAwTnIEWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "6fe27a64-6d74-4498-8bf1-36fa9a6d5c4c"
      },
      "source": [
        "from keras.optimizers import sgd\n",
        "\n",
        "modelB = create_model(x_train.shape[1:], 2, dropout_conv=0.1, dropout_classif=0.5)\n",
        "opt = sgd(lr=1e-4)\n",
        "modelB.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "modelB.fit(x_train[B_train], y_train[B_train][:,[2,4]], epochs=20, validation_data=(x_test[B_test], y_test[B_test][:,[2,4]]), verbose=2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            " - 5s - loss: 1.9456 - acc: 0.5373 - val_loss: 0.6690 - val_acc: 0.6055\n",
            "Epoch 2/20\n",
            " - 2s - loss: 0.8406 - acc: 0.5599 - val_loss: 0.6409 - val_acc: 0.6295\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.7411 - acc: 0.5729 - val_loss: 0.6347 - val_acc: 0.6405\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.7036 - acc: 0.5910 - val_loss: 0.6260 - val_acc: 0.6505\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.6850 - acc: 0.5967 - val_loss: 0.6212 - val_acc: 0.6665\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.6788 - acc: 0.5991 - val_loss: 0.6183 - val_acc: 0.6700\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.6647 - acc: 0.6132 - val_loss: 0.6135 - val_acc: 0.6800\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.6548 - acc: 0.6191 - val_loss: 0.6129 - val_acc: 0.6710\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.6455 - acc: 0.6319 - val_loss: 0.6075 - val_acc: 0.6805\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.6472 - acc: 0.6269 - val_loss: 0.6054 - val_acc: 0.6910\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.6367 - acc: 0.6432 - val_loss: 0.6037 - val_acc: 0.6930\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.6402 - acc: 0.6334 - val_loss: 0.6039 - val_acc: 0.6765\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.6299 - acc: 0.6449 - val_loss: 0.5951 - val_acc: 0.6990\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.6256 - acc: 0.6517 - val_loss: 0.5896 - val_acc: 0.7040\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.6258 - acc: 0.6570 - val_loss: 0.5892 - val_acc: 0.6995\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.6199 - acc: 0.6579 - val_loss: 0.5855 - val_acc: 0.7025\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.6177 - acc: 0.6594 - val_loss: 0.5871 - val_acc: 0.6950\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.6149 - acc: 0.6631 - val_loss: 0.5821 - val_acc: 0.7060\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.6141 - acc: 0.6648 - val_loss: 0.5798 - val_acc: 0.7095\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.6071 - acc: 0.6724 - val_loss: 0.5770 - val_acc: 0.7145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc20539f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}